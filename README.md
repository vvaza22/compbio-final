# აბსტრაქტი

ჩვენი პროექტის მიზანია, Machine Learning-ის სფეროში მიღწევები და ახალი ხელსაწყოები გამოვიყენოთ ბიოლოგიური ამოცანის ამოსახსნელად. კონკრეტულად, გვინდა, გავწვრთნათ მოდელი, რომელიც დაისწავლის თუ რა ტიპის დნმ-ის მიმდევრობებს უკავშირდება მოცემული ტრანსკრიფციის ფაქტორი და შემდეგ შეაფასებს binding score-ით ისეთ მიმდევრობებს, რომლებიც აქამდე არასდროს უნახავს. ჩვენი პროექტი დაფუძნებულია 2015 წლის ფუნდამენტურ სამეცნიერო ნაშრომზე **Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning**(https://www.nature.com/articles/nbt.3300), რომელშიც ავტორებმა შეიმუშავეს CNN მოდელი, სახელად **DeepBind**, და აჩვენეს, რომ ძველ მიდგომებს ბევრად ჯობია სხვადასხვა მეტრიკებით. ჩვენი ვაპირებთ, ჯერ გავიმეოროთ ავტორების ექსპერიმენტი **DREAM5** dataset-ზე და შემდეგ შევეცადოთ მათი მოდელის გაუმჯობესება.

# ექსპერიმენტის აღწერა

## DREAM5 Dataset

DREAM5-ში მოცემულია Protein Binding Microarray(PBM)-ში ჩატარებული ექსპერიმენტის შედეგები, რომელიც გვაჩვენებს თუ რომელ დნმ მონაკვეთებს რა ინტენსივობით უკავშირდება სხვადასხვა ტრანსკრიფციის ფაქტორები. ტრანსკრიფციის ფაქტორებზე დამატებულია ფლუორესცენციური tag-ები. მნათობი ცილები დნმ-ის სხვადასხვა მონაკვეთს უკავშირდება და საბოლოოდ თითოეული 40 ნუკლეოტიდიანი მონაკვეთის ფლუორესცენციის ინტენსივობა ითარგმნება მაგ მონაკვეთის **binding score**-ში. მონაცემების შესაგროვებლად გამოიყენეს ორი სხვადასხვა დიზაინის PBM:

- ME (Mintseris-Eisen)
- HK (Hilal Kazan)

თითოეული დიზაინს თავისი ნაკლები აქვს და მიღებული ინფორმაცია შეიძლება შეიცავდეს არტეფაქტებსა და bias-ებს. ამ პრობლემის გადასაჭრელად DREAM5-ის ავტორები გვთავაზობენ, რომ მოდელი გავწვრთნათ HK-დან მიღებულ training data-ზე და test/validation data-ად გამოვიყენოთ ME-დან მიღებული **binding score**-ები. ამ გზით ვუზრუნველყოფთ, რომ ჩვენი მოდელი PBM დიზაინის არტეფაქტებს არ იზეპირებს.

ზოგიერთ მეტრიკას სჭირდება 0/1 ლეიბელები. 1 კლასში მხოლოდ ისეთი დნმ მონაკვეთები უნდა მოვაქციოთ, რომლებზეც დიდი ალბათობით ვიტყვით, რომ ტრანსკრიფციის ფაქტორი უკავშირდება. DREAM5-ის ავტორები გვთავაზობენ, რომ ნებისმიერი ინტენსივიობა, რომელიც უფრო დიდია ვიდრე $mean + 4*std$, ჩავთვალოთ დადებით კლასში და დანარჩენი კი - უარყოფით კლასში.

## Data Preprocessing

სტატიის ავტორები გვირჩევენ, რომ მიმდევრობის სპეციფიური bias-ების გასაქრობად შეგვიძლია თითოეული მიმდევრობისათვის დავითვალოთ ყველა ცილის ამ მიმდევრობაზე binding score-ის მედიანა. შემდეგ განიხილავენ ორ ვარიანტს:

1. გამოვაკლოთ binding score-ს მედიანა
1. გავყოთ binding score მედიანაზე

ეს მიდგომა Data Leak-ს არ იწვევს Train/Test-ს შორის, რადგან მხოლოდ 1 მიმდევრობის ჭრილში ვასრულებთ ამ ოპერაციას.

ჩემს ექსპერიმენტებში ორივე Preprocessing ვცადე. ზოგ ცილაზე პირველმა უკეთესი შედეგი მომცა, ზოგზე კი - მეორემ.

საბოლოოდ binding score-ები მათემატიკურად ნორმალიზდება $mean$-ის გამოკლებითა და $std$-ზე გაყოფით. Data Leak-ის თავიდან ასარიდებლად Test set-საც იმავე პარამეტრებით ვანორმალიზებ, რაც train set-დან დავითვალე.

სტატია ასევე გვთავაზობს Reverse Complement Mode-ის დამატებას. როდესაც შედეგები მიღებულია ორჯაჭვიანი დნმ-დან, გაურკვეველია ცილა იმ მიმდევრობას დაუკავშირდა, რომელიც dataset-ში არის მოცემული თუ მის კომპლემენტალურ მიმდევრობას. ამიტომაც Data Augmentation უნდა დავამატოთ, რომელიც 0.5 ალბათობით მიმდევრობას მისი კომპლემენტალურით შეცვლის.

ოპტიმიზაციის დამატება შესაძლებელია Evaluation-ის დროსაც. როდესაც მიმდევრობა შემოუვა მოდელს, იგი forward pass-ს ორჯერ გაუშვებს. ერთს ორიგინალ მიმდევრობაზე და მეორეს მის კომპლემენტალურზე. ორი შედეგიდან იგი დააბრუნებს ყველაზე მაღალ binding score-ს.

## DeepBind მოდელი

DeepBind არის Convolutional Neural Network შემდეგი არქიტექტურით:

$$ f(x) = net(MaxPool(ReLU(conv(x)))) $$

დნმ-ის მიმდევრობა რაიმე საშუალებით უნდა გადაკეთდეს **4xN** ზომის მატრიცად და ისე გადაეცეს მოდედლს. მოდელმა უნდა დაამუშაოს მიღებული მიმდევრობა და საბოლოოდ მიანიჭოს **binding score**.

_LaTeX_ ჩანაწერში $net()$ გულისხმობს Fully Connected Network-ს, რომელიც შეიძლება იყოს ერთი ან ორფენიანი.

ასევე, როგორც სტატია აღნიშნავს, რეგულარიზაციისათვის მნიშვნელოვანია, რომ $MaxPool()$ ფენის შემდეგ და, ბოლოს გარდა, ყოველი Fully Connected ფენის შემდეგ დავსვათ $dropout()$ ფენა, რათა თავი დავიცვათ train set-ზე overfit-ისგან.

უკანასკნელი Fully Conneclted ფენის პასუხისმგებლობაა წინა ფენიდან მიღებული ინფორმაცია გადააქციოს სკალარ **binding score**-ად.

## Training

**Loss** ფუნქციად, როგორც სტატიაში, გამოვიყენებ **Mean Squared Error(MSE)**-ს მიმდევრობის ნამდვილ binding score-სა და მოდელის predicted binding score-ს შორის.

სტატია გვაფრთხილებს, რომ წონების ინიციალიზაციზე ძალიან სენსიტიურია training და ეს ჩემი ექსპერიმენტებითაც დადასტურდა. ინიციალიზაციის ჰიპერპარამეტრების შესარჩევად ვიყენებ GridSearch-ს პარამეტრების სხვადასხვა კომბინაციაზე, მიღებულ მოდელებსა და შედეგებს ვტვირთავ **WanDB**-ის პლატფორმაზე და შემდეგ ამოვარჩევ საუკეთესო მოდელებს.

ძალზე მნიშვნელოვანია თავიდან ავირიდოთ training data-ზე overfit. მოდელი უნდა გაიწვრთნას ძლიერი რეგულარიზაციით: dropout, weight decay. ამასთანავე, როგორც სტატიის ავტორებმა გვირჩიეს, დავაიმპლემენტირე early stopping, რომელიც აკვირდება ვალიდაციის მონაცემებს და ეპოქის შემდეგ თუ 0.001 threashold-ზე უფრო მეტად გაუარესდა training-ს წყვეტს.

## Evaluation მეტრიკები

**Pearson** - გვიჩვენებს predicted და actual binding score-ებს შორის არსებობს თუ არა წრფივი დამოკიდებულება. თუ pearson=1 predicted და actual ქულები წრფეზე განლაგდებიან.

**ROC Curve და AUC** - მაშინ გამოიყენება, როდესაც გვინდა, რომ 1/0 label მივანიჭოთ მოდელის predicted binding score-ებს. იგი გვიჩვენებს threashold-ის მოძრაობისას, როგორ იცვლება True Positive Rate და False Positive Rate. იდეალურად გვინდა, რომ False Positive-ები არ გვქონდეს და ყველა ნეგატიურ label-ს ძალიან დაბალი binding score მიანიჭოს მოდელმა. ამ შემთხვევაში ROC მრუდის ქვემოთ ფართობი 1.0 იქნება. რეალურად მოდელი უნაკლო არ არის და ზოგ მიმდევრობას მცდარად მიანიჭებს მაღალ binding score-ს. იგი იქნება False Positive. AUC(Area Under the Curve)-ით შეგვიძლია გავიგოთ თუ რამდენად ხშირია ასეთი ტიპის შეცდომები. იგი გასცემს შეკითხვას პასუხს: შემთხვევითად ერთი ნეგატიური ლეიბელის მქონე მიმდევრობა რომ ავიღო და ერთი - პოზიტიური ლეიბელის, რამდენად ხშირად მიანიჭებს მოდელი პოზიტიურ ლეიბელს უფრო მაღალ ქულას. თუ AUC=0.5 მოდელი საერთოდ არ მუშაობს და შემთხვევითად ანიჭებს ქულებს.

![ROC Curve](images/roc.png)
_Figure 1. ROC Curve. წყარო: https://en.wikipedia.org/wiki/Receiver_operating_characteristic#/media/File:Roc_curve.svg_

# ექსპერიმენტის რეპლიკაცია

**კოდის ფაილი: DeepBind_Baseline.ipynb**

Jupyter Notebook-ში ავაწყვე მოდელის ყველა დეტალი ზუსტად ისე, როგორც სტატიის **Supplementary Notes**-ში იყო მითითებული. გამოვიყენე ის ყველა Preprocessing, Training მიდგომა, რომელზეც ზემოთ ვისაუბრე. ავიღე 5 ტრანსკრიფციის ფაქტორი, რომელზეც მინდოდა ავტორების შედეგის გამეორება და WanDB-ზე დაახლოები 200-300 მოდელი დავლოგე GridSearch-ით თითოეული ტრანსკრიფციის ფაქტორისათვის. Pearson და AUC მეტრიკები შემოწმებულია Test Set-ზე.

### TF_2

| Model               | Pearson | AUC   |
| ------------------- | ------- | ----- |
| Original DeepBind   | 0.651   | 0.986 |
| ჩვენი იმპლემენტაცია | 0.635   | 0.978 |

https://wandb.ai/vvaza22-free-university-of-tbilisi/CompBioBaseline__TF_2/runs/0c94joeh

### TF_6

| Model               | Pearson | AUC   |
| ------------------- | ------- | ----- |
| Original DeepBind   | 0.473   | 0.990 |
| ჩვენი იმპლემენტაცია | 0.483   | 0.971 |

https://wandb.ai/vvaza22-free-university-of-tbilisi/CompBioBaseline__TF_6/runs/2ulbvysu

### TF_9

| Model               | Pearson | AUC   |
| ------------------- | ------- | ----- |
| Original DeepBind   | 0.613   | 0.874 |
| ჩვენი იმპლემენტაცია | 0.633   | 0.950 |

https://wandb.ai/vvaza22-free-university-of-tbilisi/CompBioBaseline__TF_9/runs/rg5vgj07

### TF_12

| Model               | Pearson | AUC   |
| ------------------- | ------- | ----- |
| Original DeepBind   | 0.726   | 0.933 |
| ჩვენი იმპლემენტაცია | 0.706   | 0.948 |

https://wandb.ai/vvaza22-free-university-of-tbilisi/CompBioBaseline__TF_12/runs/wqp9jayg

### TF_31

| Model               | Pearson | AUC   |
| ------------------- | ------- | ----- |
| Original DeepBind   | 0.843   | 0.957 |
| ჩვენი იმპლემენტაცია | 0.850   | 0.971 |

https://wandb.ai/vvaza22-free-university-of-tbilisi/CompBioBaseline__TF_31/runs/ceqnmcex

შევძელი, რომ ავტორების მიღებული შედეგები გამემეორებინა ძალიან მცირე ცდომილებით. ზოგი ცილის შემთხვევაში ორიგინალი DeepBind უფრო კარგ შედეგს იძლევა, ზოგ შემთხვევაში კი ჩვენი იმპლემენტაცია ჯობნის. ეს მოსალოდნელია, რადგან ძალიან რთული დავალებაა მრავალგანზომილებიანი პარამეტრების სივრცეში ზუსტად იმავე ლოკალურ მინიმუმში ჩააგდო მოდელი, რომელსაც სტატიის ავტორებმა მიაღწიეს 2015 წელს. იქიდან გამომდინარე, რომ ცდომილება მინიმალურია, შემიძლია ჩავთვალო, რომ ექსპერიმენტი წარმატებით გავიმეორე.

## ბიოლოგიური ინტერპრეტაცია

ერთ-ერთი საინტერესო იდეა, რომელსაც სტატიამ ხაზი გაუსვა, არის ის, რომ კონვოლუციური ფენების ფილტრებს შეგვიძლია შევხედოთ ისე, როგორც PWM-ებს და მისი გამოყენებით ავაგოთ Sequence Logo. შესაბამისად გვეცოდინება თუ კონკრეტულად რას უყურებს კონვოლუციური ფენის მოცემული ფილტრი.

ეს ექსპერიმენტი ჩავატარე **TF_2**-ის საუკეთესო მოდელის რამდენიმე ფილტრზე. ფილტრის წონები ჯერ დავანორმალიზე, ისე რომ ალბათობები გამოსულიყო და შემდეგ logomaker ბიბლიოთეკით ავაგე Sequence Logo.

![TF_2 Motif](images/motif_1.png)
_Figure 2. Sequence Logo TF_2 ფილტრიდან_

DREAM5-ის სტატიაში TF_2 ცილისთვის მოცემულია სხვა მეთოდებით მიღებული Sequence Logo-ები:

![TF_2 Motifs by other methods](images/real_motifs.png)
_Figure 3. Sequence Logo სხვა მეთოდებით. წყარო: https://pmc.ncbi.nlm.nih.gov/articles/instance/3687085/bin/NIHMS399608-supplement-Suppl_Materials.pdf_

აქედან გამომდინარე, აშკარაა რომ ჩემ მიერ მიღებული Sequence Logo ცილის მოტივის შესახებ იძლევა ინფორმაციას. ყველა მიდგომაში ფიგურირებს მიმდევრობა **TTA..TAA**.

ვფიქრობ ძალიან საინტერესოა, რომ კონვოლუციურმა ფილტრმა თავისით დაისწავლა თუ როგორ გამოიყურება მოტივი. ფილტრების ლოგოებად წარმოდგენა ძალიან მარტივი გზა არის ML-ის სამყაროდან ბიოლოგიის სამყაროში გადასასვლელად.

# გამოყენებული რესურსები

## მთავარი სტატია

**Nature Biotechnology:**

https://www.nature.com/articles/nbt.3300

**საჯაროდ ხელმისაწვდომი ვერსია(Research Gate):**

https://www.researchgate.net/publication/280496611_Predicting_the_sequence_specificities_of_DNA-_and_RNA-binding_proteins_by_deep_learning

**მოდელის იმპლემენტაციის დეტალები(Supplementary notes):**

https://static-content.springer.com/esm/art%3A10.1038%2Fnbt.3300/MediaObjects/41587_2015_BFnbt3300_MOESM51_ESM.pdf

## DREAM5 Challenge Dataset

Challenge-ის დეტალები და Evaluation წესები:

https://pmc.ncbi.nlm.nih.gov/articles/PMC3687085/

Dataset-ის ფაილები აღებულია შემდეგი ლინკიდან:

https://github.com/jisraeli/DeepBind/tree/master/data/dream5

# პროექტის ავტორები

ვასიკო ვაზაგაევი

დაჩი სურამელაშვილი

გიორგი ებანოიძე

ლუკა ტურაბელიძე
